import logging

from bailiff.features.assistant.llm import LLMClient
from bailiff.features.memory.storage import MeetingStorage

logger = logging.getLogger("bailiff.features.analysis.digester")

# TODO: Improve the digestion context with Topic/Domain, Language, etc.

class Digester:
    """
    Processes raw transcripts to create a clean, readable, and accurate version using LLM-based correction.
    
    This class handles the interaction with the LLM to refine the raw ASR output, correcting errors,
    improving punctuation, and formatting the text into a structured markdown format with speaker labels.
    """

    DIGESTION_PROMPT = """
    System Context:
    You are an expert multilingual transcription editor. Your task is to take a raw, unedited transcription generated by an automatic speech recognition (ASR) system like Whisper—often containing errors, especially in non-English languages—and refine it into a clean, readable, and accurate version. The output must be in Markdown format.

    Instructions:
    1. Fix transcription errors - Correct misspelled words, phonetic misinterpretations, homophone mistakes (e.g., “their” vs “there”), garbled phrases, and any nonsensical sequences. Use context and your knowledge of multiple languages to infer the intended words.
    2. Improve punctuation & capitalization - Add proper sentence capitalization, periods, commas, question marks, and quotation marks where appropriate. 
    3. Handle multiple languages hallucination, if a phrase is in a language other than the one being often transcribed, mark it as [inaudible].
    4. Refine the transcription by replacing individual words or sequential phrases that lack clarity or logical flow, ensuring the final text is coherent and accurate.
    5. Handle filler words and disfluencies - Words like “um”, “uh”, “like”, “you know”, repeated false starts, or stutters. Use your judgment:
        - If the filler adds natural conversational rhythm, keep it (e.g., “Well, um, I think…”).
        - If it's excessive and impedes clarity, remove it or reduce it.
        - Aim for a natural, clean transcript that still sounds like the speaker.
    6. Preserve original meaning and content - Do not paraphrase, summarize, or add new information. Only correct and clarify what was said.

    Strictly follow this Markdown structure:
    ```markdown
    [Cleaned transcript with speaker labels]
    .e.g. 
    ### Cleaned Transcript
    *Speaker 0*: The people are going to enjoy. So, dude, go there and enjoy.
    *Speaker 0*: That place.
    *Speaker 1*: Vocal technique.
    ...
    ```

    Only respond with the Markdown structure above. Do not include any additional text.
    """

    def __init__(self, storage: MeetingStorage, llm: LLMClient):
        self.storage = storage
        self.llm = llm

    def digest(self, session_id: int) -> str:
        """
        Digests the raw transcript into a clean, readable, and accurate version.

        Uses the LLM to do a pre-processing, cleaning the transcript and removing any errors or hallucinations.

        Args:
            session_id (int): The ID of the session to digest.

        Returns:
            str: The cleaned transcript.
        """

        logger.info(f"Digesting session {session_id}")
        
        session = self.storage.get_session(session_id)
        if not session:
            logger.error(f"Session {session_id} not found!")
            raise ValueError(f"Session {session_id} not found!")
        
        transcripts = self.storage.get_transcripts(session_id)

        if not transcripts:
            logger.warning(f"Session {session_id} has no transcripts to digest")
            return ""
        logger.info(f"Digesting session {session.name}")

        raw_transcript_text = "\n".join([f"{t.speaker}: {t.text}" for t in transcripts])
        
        messages = [
            {"role": "system", "content": self.DIGESTION_PROMPT},
            {"role": "user", "content": raw_transcript_text}
        ]

        return self.llm.chat(messages)


if __name__ == "__main__":
    """
    Example of how to use the digester.
    """
    
    import logging
    from bailiff.features.memory.storage import MeetingStorage
    from bailiff.features.assistant.llm import LLMClient
    from bailiff.core.db import SessionLocal
    from bailiff.core.config import settings

    api_key = settings.models.llm_api_key.get_secret_value() if settings.models.llm_api_key else None
    base_url = settings.models.llm_base_url
    digestion_model = settings.models.llm_digestion

    logging.basicConfig(level=logging.INFO)
    
    storage = MeetingStorage(db=SessionLocal())
    llm_settings = LLMClientSettings(api_key=api_key, base_url=base_url, model=digestion_model)
    llm = LLMClient(settings=llm_settings)
    digester = Digester(storage, llm)
    
    try:
        result = digester.digest(17)
        print("\n--- Digestion Result ---\n")
        print(result)
    except Exception as e:
        logger.error(f"Failed to digest session: {e}")
    
        